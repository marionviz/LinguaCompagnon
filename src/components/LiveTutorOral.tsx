// src/components/LiveTutorOral.tsx
// VERSION HYBRIDE : Web Speech API + Gemini Chat + Google Cloud TTS

import React, { useEffect, useRef, useState, useCallback } from 'react';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { ConnectionState, Correction } from '../typesOral';
import { getOralWeekConfig } from '../constantsOral';
import { useToolBox } from '../hooks/useToolBox';
import { ToolBox } from './ToolBox/ToolBox';

interface LiveTutorOralProps {
  weekNumber: number;
  onClose: () => void;
}

const LiveTutorOral: React.FC<LiveTutorOralProps> = ({ weekNumber, onClose }) => {
  const week = getOralWeekConfig(weekNumber);
  const { addItem } = useToolBox();
  
  const [connectionState, setConnectionState] = useState<ConnectionState>(ConnectionState.DISCONNECTED);
  const [transcript, setTranscript] = useState<string>('');
  const [conversationHistory, setConversationHistory] = useState<Array<{role: 'user' | 'model', parts: Array<{text: string}>}>>([]);
  const [corrections, setCorrections] = useState<Correction[]>([]);
  const [errorMsg, setErrorMsg] = useState<string | null>(null);
  const [showToolbox, setShowToolbox] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);

  const recognitionRef = useRef<any>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const geminiChatRef = useRef<any>(null);
  const isListeningRef = useRef(false);

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // INITIALISATION GEMINI CHAT
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  
  useEffect(() => {
    initializeGemini();
    return () => {
      cleanup();
    };
  }, []);

  const initializeGemini = async () => {
    try {
      const apiKey = import.meta.env.VITE_API_KEY;
      if (!apiKey) throw new Error("VITE_API_KEY manquante");

      const ai = new GoogleGenerativeAI(apiKey);
      const model = ai.getGenerativeModel({ 
        model: 'gemini-2.0-flash-exp',
        systemInstruction: week.systemPrompt
      });

      const chat = model.startChat({
        history: [],
      });

      geminiChatRef.current = chat;
      console.log('‚úÖ Gemini Chat initialis√©');
    } catch (err) {
      console.error('‚ùå Erreur initialisation Gemini:', err);
      setErrorMsg('Erreur initialisation IA');
      setConnectionState(ConnectionState.ERROR);
    }
  };

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // RECONNAISSANCE VOCALE (Web Speech API)
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  const startListening = useCallback(() => {
    if (isListeningRef.current || isSpeaking) return;

    try {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      if (!SpeechRecognition) {
        throw new Error('Speech Recognition non support√©');
      }

      const recognition = new SpeechRecognition();
      recognition.lang = 'fr-FR';
      recognition.continuous = false;
      recognition.interimResults = false;

      recognition.onstart = () => {
        console.log('üé§ √âcoute d√©marr√©e');
        isListeningRef.current = true;
        setTranscript('');
      };

      recognition.onresult = async (event: any) => {
        const userText = event.results[0][0].transcript;
        console.log('üìù Transcription:', userText);
        setTranscript(userText);
        isListeningRef.current = false;

        // Ajouter √† l'historique
        setConversationHistory(prev => [...prev, { 
          role: 'user', 
          parts: [{ text: userText }] 
        }]);

        // Envoyer √† Gemini
        await sendToGemini(userText);
      };

      recognition.onerror = (event: any) => {
        console.error('‚ùå Erreur reconnaissance:', event.error);
        isListeningRef.current = false;
        if (event.error !== 'no-speech') {
          setErrorMsg('Erreur reconnaissance vocale');
        }
      };

      recognition.onend = () => {
        console.log('üé§ √âcoute termin√©e');
        isListeningRef.current = false;
      };

      recognitionRef.current = recognition;
      recognition.start();

    } catch (err: any) {
      console.error('‚ùå Erreur d√©marrage reconnaissance:', err);
      setErrorMsg('Microphone non accessible');
      setConnectionState(ConnectionState.ERROR);
    }
  }, [isSpeaking]);

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // GEMINI CHAT (Analyse + Corrections)
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  const sendToGemini = async (userText: string) => {
    try {
      if (!geminiChatRef.current) {
        throw new Error('Gemini non initialis√©');
      }

      console.log('üîÑ Envoi √† Gemini...');
      const result = await geminiChatRef.current.sendMessage(userText);
      const response = result.response.text();
      
      console.log('‚úÖ R√©ponse Gemini:', response);

      // Ajouter √† l'historique
      setConversationHistory(prev => [...prev, { 
        role: 'model', 
        parts: [{ text: response }] 
      }]);

      // Parser les corrections
      const extractedCorrections = extractCorrections(response, userText);
      
      if (extractedCorrections.length > 0) {
        setCorrections(prev => [...prev, ...extractedCorrections]);
        saveCorrectionsToToolBox(extractedCorrections);
      }

      // Synth√©tiser la voix avec Google TTS
      await speakWithGoogleTTS(response);

      // Relancer l'√©coute apr√®s que Fran√ßois ait parl√©
      setTimeout(() => {
        if (connectionState === ConnectionState.CONNECTED) {
          startListening();
        }
      }, 500);

    } catch (err: any) {
      console.error('‚ùå Erreur Gemini:', err);
      setErrorMsg('Erreur traitement IA');
      setConnectionState(ConnectionState.ERROR);
    }
  };

  // Extraction des corrections
  const extractCorrections = (response: string, originalText: string): Correction[] => {
    const corrections: Correction[] = [];
    
    const correctionPatterns = [
      /(?:erreur|incorrect|faux|attention).*?["¬´](.+?)["¬ª].*?(?:devrait √™tre|dire|correct).*?["¬´](.+?)["¬ª]/gi,
      /["¬´](.+?)["¬ª].*?(?:‚Üí|=>|devrait √™tre|correct).*?["¬´](.+?)["¬ª]/gi
    ];

    for (const pattern of correctionPatterns) {
      let match;
      while ((match = pattern.exec(response)) !== null) {
        corrections.push({
          originalSentence: match[1].trim(),
          correctedSentence: match[2].trim(),
          explanation: 'Correction identifi√©e',
        });
      }
    }

    return corrections;
  };

  // Sauvegarder dans la ToolBox
  const saveCorrectionsToToolBox = (corrections: Correction[]) => {
    corrections.forEach(correction => {
      addItem({
        category: 'grammar',
        title: 'Correction orale',
        description: correction.explanation,
        example: `‚ùå "${correction.originalSentence}"\n‚úÖ "${correction.correctedSentence}"`,
        errorContext: `Semaine ${weekNumber}`,
      });
    });

    window.dispatchEvent(new Event('toolboxUpdated'));
  };

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // GOOGLE CLOUD TEXT-TO-SPEECH (Voix fran√ßaise native)
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  const speakWithGoogleTTS = async (text: string) => {
    try {
      setIsSpeaking(true);
      console.log('üîä Synth√®se vocale Google TTS...');

      const apiKey = import.meta.env.VITE_API_KEY;
      
      const response = await fetch(
        `https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            input: { text },
            voice: {
              languageCode: 'fr-FR',
              name: 'fr-FR-Neural2-B', // ‚úÖ Voix masculine fran√ßaise native
            },
            audioConfig: {
              audioEncoding: 'MP3',
              pitch: 0,
              speakingRate: 1.0
            }
          })
        }
      );

      if (!response.ok) {
        throw new Error(`TTS API error: ${response.status}`);
      }

      const data = await response.json();
      const audioContent = data.audioContent;

      await playAudioBase64(audioContent);

      console.log('‚úÖ Audio jou√©');
      setIsSpeaking(false);

    } catch (err: any) {
      console.error('‚ùå Erreur TTS:', err);
      setIsSpeaking(false);
      
      // Fallback : synth√®se navigateur
      console.log('üîÑ Fallback vers synth√®se navigateur...');
      await speakWithBrowserTTS(text);
    }
  };

  // Fallback : Synth√®se vocale navigateur
  const speakWithBrowserTTS = async (text: string) => {
    return new Promise<void>((resolve, reject) => {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'fr-FR';
      utterance.rate = 1.0;
      utterance.pitch = 1.0;

      const voices = speechSynthesis.getVoices();
      const frenchVoice = voices.find(v => v.lang.startsWith('fr'));
      if (frenchVoice) {
        utterance.voice = frenchVoice;
      }

      utterance.onend = () => {
        setIsSpeaking(false);
        resolve();
      };

      utterance.onerror = (err) => {
        console.error('‚ùå Erreur synth√®se navigateur:', err);
        setIsSpeaking(false);
        reject(err);
      };

      speechSynthesis.speak(utterance);
    });
  };

  // Jouer l'audio depuis base64
  const playAudioBase64 = async (base64Audio: string) => {
    try {
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      }

      const audioContext = audioContextRef.current;
      
      const binaryString = atob(base64Audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);

      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);

      return new Promise<void>((resolve) => {
        source.onended = () => resolve();
        source.start(0);
      });

    } catch (err) {
      console.error('‚ùå Erreur lecture audio:', err);
      throw err;
    }
  };

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // D√âMARRAGE SESSION
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  const startSession = async () => {
    try {
      setConnectionState(ConnectionState.CONNECTING);
      setErrorMsg(null);
      setCorrections([]);
      setConversationHistory([]);

      // V√©rifier le micro
      await navigator.mediaDevices.getUserMedia({ audio: true });

      console.log('‚úÖ Session d√©marr√©e');
      setConnectionState(ConnectionState.CONNECTED);

      // Message d'accueil
      const greeting = `Bonjour ! Je suis Fran√ßois, votre tuteur de fran√ßais. Nous travaillons sur la semaine ${weekNumber}. Commen√ßons !`;
      await speakWithGoogleTTS(greeting);

      // D√©marrer l'√©coute apr√®s l'accueil
      setTimeout(() => {
        startListening();
      }, 500);

    } catch (err: any) {
      console.error('‚ùå Erreur d√©marrage:', err);
      setErrorMsg('Impossible d\'acc√©der au microphone');
      setConnectionState(ConnectionState.ERROR);
    }
  };

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // CLEANUP
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  const cleanup = () => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {}
      recognitionRef.current = null;
    }

    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    speechSynthesis.cancel();
    isListeningRef.current = false;
  };

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // RENDU UI
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  const getStateDisplay = () => {
    if (isSpeaking) {
      return { icon: 'üîä', text: 'Fran√ßois parle...', color: 'text-blue-500' };
    }
    if (isListeningRef.current) {
      return { icon: 'üé§', text: 'Je vous √©coute...', color: 'text-purple-500 animate-pulse' };
    }

    switch (connectionState) {
      case ConnectionState.DISCONNECTED:
        return { icon: '‚ö™', text: 'D√©connect√©', color: 'text-gray-500' };
      case ConnectionState.CONNECTING:
        return { icon: 'üîÑ', text: 'Connexion...', color: 'text-blue-500' };
      case ConnectionState.CONNECTED:
        return { icon: 'üü¢', text: 'Connect√©', color: 'text-green-500' };
      case ConnectionState.ERROR:
        return { icon: '‚ùå', text: 'Erreur', color: 'text-red-500' };
      default:
        return { icon: '‚ö™', text: 'Inconnu', color: 'text-gray-500' };
    }
  };

  const stateDisplay = getStateDisplay();

  return (
    <div className="flex flex-col h-screen max-w-6xl mx-auto bg-gradient-to-br from-purple-50 via-white to-blue-50">
      {/* HEADER */}
      <header className="p-6 border-b bg-white/80 backdrop-blur-sm">
        <div className="flex items-center justify-between">
          <div>
            <h1 className="text-2xl font-bold text-gray-800">
              üé§ Fran√ßois - Mode Oral Hybride
            </h1>
            <p className="text-sm text-gray-600">Semaine {weekNumber} ‚Ä¢ Voix fran√ßaise native</p>
          </div>
          <button
            onClick={onClose}
            className="px-4 py-2 text-sm text-gray-700 hover:text-gray-900 border border-gray-300 rounded-lg hover:bg-gray-50 transition-colors"
          >
            ‚Üê Retour
          </button>
        </div>
      </header>

      {/* MAIN */}
      <main className="flex-1 flex flex-col items-center justify-center p-6">
        {connectionState === ConnectionState.DISCONNECTED && (
          <div className="text-center">
            <button
              onClick={startSession}
              className="px-8 py-4 bg-gradient-to-r from-green-500 to-emerald-600 text-white rounded-full text-lg font-semibold shadow-lg hover:shadow-xl hover:scale-105 transition-all"
            >
              üé§ D√©marrer la conversation
            </button>
            <p className="mt-4 text-sm text-gray-600">
              Solution hybride : Gemini Chat + Google TTS
            </p>
          </div>
        )}

        {connectionState === ConnectionState.CONNECTING && (
          <div className="text-center">
            <div className="w-24 h-24 border-8 border-blue-200 border-t-blue-600 rounded-full animate-spin mx-auto mb-4"></div>
            <p className="text-lg text-gray-700">Connexion...</p>
          </div>
        )}

        {connectionState === ConnectionState.CONNECTED && (
          <div className="text-center">
            <div className={`w-48 h-48 rounded-full flex items-center justify-center text-6xl shadow-2xl mb-6 ${
              isSpeaking ? 'bg-gradient-to-br from-blue-400 to-cyan-500 animate-pulse' :
              isListeningRef.current ? 'bg-gradient-to-br from-purple-400 to-pink-500 animate-pulse' :
              'bg-gradient-to-br from-green-400 to-emerald-500'
            }`}>
              {stateDisplay.icon}
            </div>

            <div className={`text-xl font-semibold ${stateDisplay.color} mb-4`}>
              {stateDisplay.text}
            </div>

            {transcript && (
              <div className="bg-white border border-gray-200 rounded-lg p-4 max-w-2xl mb-4">
                <p className="text-sm text-gray-600 mb-1">Vous avez dit :</p>
                <p className="text-gray-800">{transcript}</p>
              </div>
            )}

            {!isSpeaking && !isListeningRef.current && (
              <p className="text-sm text-gray-500">
                Fran√ßois vous √©coute automatiquement...
              </p>
            )}
          </div>
        )}

        {connectionState === ConnectionState.ERROR && (
          <div className="text-center">
            <div className="text-6xl mb-4">‚ùå</div>
            <p className="text-xl text-red-600 mb-4">Erreur</p>
            <p className="text-gray-600 mb-4">{errorMsg}</p>
            <button
              onClick={startSession}
              className="px-6 py-3 bg-red-500 text-white rounded-lg hover:bg-red-600 transition-colors"
            >
              R√©essayer
            </button>
          </div>
        )}
      </main>

      {/* TOOLBOX */}
      <div className="border-t bg-white p-4">
        <button
          onClick={() => setShowToolbox(!showToolbox)}
          className="w-full flex items-center justify-between hover:bg-gray-50 p-2 rounded transition-colors"
        >
          <div className="flex items-center gap-2">
            <span className="text-xl">üõ†Ô∏è</span>
            <span className="font-semibold text-gray-800">Bo√Æte √† Outils</span>
            {corrections.length > 0 && (
              <span className="bg-red-500 text-white text-xs px-2 py-1 rounded-full">
                {corrections.length}
              </span>
            )}
          </div>
          <svg 
            className={`w-5 h-5 transition-transform ${showToolbox ? 'rotate-180' : ''}`} 
            fill="none" 
            viewBox="0 0 24 24" 
            stroke="currentColor"
          >
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 9l-7 7-7-7" />
          </svg>
        </button>

        {showToolbox && (
          <div className="mt-4">
            <ToolBox weekNumber={weekNumber} />
          </div>
        )}
      </div>
    </div>
  );
};

export default LiveTutorOral;