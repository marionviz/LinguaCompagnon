// src/components/LiveTutorOral.tsx
// VERSION FINALE : TTS + Corrections automatiques + ToolBox

import React, { useEffect, useRef, useState, useCallback } from 'react';
import { GoogleGenerativeAI, FunctionDeclaration, SchemaType } from '@google/generative-ai';
import { ConnectionState, Correction } from '../typesOral';
import { getOralWeekConfig } from '../constantsOral';
import { useToolBox } from '../hooks/useToolBox';
import { ToolBox } from './ToolBox/ToolBox';

interface LiveTutorOralProps {
  weekNumber: number;
  onClose: () => void;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FUNCTION DECLARATION POUR CORRECTIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const correctionTool: FunctionDeclaration = {
  name: "signaler_correction",
  description: `Signaler UNE correction Ã  la fois quand l'apprenant fait une erreur.

RÃˆGLES STRICTES :
âœ… Corriger UNIQUEMENT les VRAIES erreurs importantes
âŒ NE JAMAIS corriger si phrases identiques
âŒ NE JAMAIS inventer des erreurs

TYPES D'ERREURS :
- grammar : articles, accords, structure
- conjugation : temps verbal, auxiliaire
- vocabulary : mot inexistant
- pronunciation : liaisons interdites

EXEMPLES :
âœ… "Je suis allÃ© Ã  la Paris" â†’ "Je suis allÃ© Ã  Paris" (grammar)
âœ… "Hier je mange" â†’ "Hier j'ai mangÃ©" (conjugation)
âŒ NE PAS corriger si dÃ©jÃ  correct`,
  
  parameters: {
    type: SchemaType.OBJECT,
    properties: {
      originalSentence: { 
        type: SchemaType.STRING, 
        description: "Phrase EXACTE avec l'erreur" 
      },
      correctedSentence: { 
        type: SchemaType.STRING, 
        description: "Version CORRIGÃ‰E (doit Ãªtre diffÃ©rente)" 
      },
      explanation: { 
        type: SchemaType.STRING, 
        description: "Explication brÃ¨ve (max 15 mots)" 
      },
      errorType: {
        type: SchemaType.STRING,
        description: "Type: pronunciation, grammar, vocabulary, conjugation",
        enum: ["pronunciation", "grammar", "vocabulary", "conjugation"]
      }
    },
    required: ["originalSentence", "correctedSentence", "explanation", "errorType"],
  },
};

const LiveTutorOral: React.FC<LiveTutorOralProps> = ({ weekNumber, onClose }) => {
  const week = getOralWeekConfig(weekNumber);
  const { addItem } = useToolBox();
  
  // Ã‰tats
  const [showDurationSelector, setShowDurationSelector] = useState(true);
  const [selectedDuration, setSelectedDuration] = useState<number | null>(null);
  const [timeRemaining, setTimeRemaining] = useState<number>(0);
  const [connectionState, setConnectionState] = useState<ConnectionState>(ConnectionState.DISCONNECTED);
  const [transcript, setTranscript] = useState<string>('');
  const [allCorrections, setAllCorrections] = useState<Correction[]>([]);
  const [errorMsg, setErrorMsg] = useState<string | null>(null);
  const [showToolbox, setShowToolbox] = useState(false);
  const [showToolboxNotification, setShowToolboxNotification] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isManualMode, setIsManualMode] = useState(false);

  // Refs
  const recognitionRef = useRef<any>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const geminiChatRef = useRef<any>(null);
  const isListeningRef = useRef(false);
  const timerIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const lastTranscriptRef = useRef<string>('');

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // TIMER
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  useEffect(() => {
    if (selectedDuration && connectionState === ConnectionState.CONNECTED && timeRemaining > 0) {
      timerIntervalRef.current = setInterval(() => {
        setTimeRemaining(prev => {
          if (prev <= 1) {
            handleEndCall();
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
      return () => {
        if (timerIntervalRef.current) clearInterval(timerIntervalRef.current);
      };
    }
  }, [selectedDuration, connectionState, timeRemaining]);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // INITIALISATION GEMINI AVEC FUNCTION CALLING
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  useEffect(() => {
    initializeGemini();
    return () => {
      cleanup();
    };
  }, []);

  const initializeGemini = async () => {
    try {
      const apiKey = import.meta.env.VITE_API_KEY;
      if (!apiKey) throw new Error("VITE_API_KEY manquante");

      const ai = new GoogleGenerativeAI(apiKey);
      
      // âœ… AVEC FUNCTION CALLING pour corrections
      const model = ai.getGenerativeModel({ 
        model: 'gemini-2.5-flash-preview-tts',
        systemInstruction: week.systemPrompt,
        tools: [{ functionDeclarations: [correctionTool] }],
      });

      const chat = model.startChat({
        history: [],
      });

      geminiChatRef.current = chat;
      console.log('âœ… Gemini Chat initialisÃ© avec function calling');
    } catch (err) {
      console.error('âŒ Erreur initialisation Gemini:', err);
      setErrorMsg('Erreur initialisation IA');
      setConnectionState(ConnectionState.ERROR);
    }
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RECONNAISSANCE VOCALE
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const startListening = useCallback(() => {
    if (isListeningRef.current || isSpeaking) {
      console.log('â¸ï¸ Ã‰coute dÃ©jÃ  active ou FranÃ§ois parle');
      return;
    }

    try {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      if (!SpeechRecognition) {
        throw new Error('Speech Recognition non supportÃ©');
      }

      const recognition = new SpeechRecognition();
      recognition.lang = 'fr-FR';
      recognition.continuous = false;
      recognition.interimResults = false;

      recognition.onstart = () => {
        console.log('ğŸ¤ Ã‰coute dÃ©marrÃ©e');
        isListeningRef.current = true;
        setTranscript('');
      };

      recognition.onresult = async (event: any) => {
        const userText = event.results[0][0].transcript.trim();
        const confidence = event.results[0][0].confidence;
        
        console.log('ğŸ“ Transcription:', userText);
        console.log('   Confiance:', confidence);
        
        // Ignorer si identique
        if (userText === lastTranscriptRef.current) {
          console.log('âš ï¸ Identique, ignorÃ©e');
          isListeningRef.current = false;
          if (!isManualMode) {
            setTimeout(() => startListening(), 2000);
          }
          return;
        }

        // Ignorer si trop court
        if (userText.length < 3) {
          console.log('âš ï¸ Trop courte');
          isListeningRef.current = false;
          if (!isManualMode) {
            setTimeout(() => startListening(), 2000);
          }
          return;
        }

        console.log('âœ… Transcription acceptÃ©e');
        lastTranscriptRef.current = userText;
        setTranscript(userText);
        isListeningRef.current = false;

        // Envoyer Ã  Gemini
        await sendToGemini(userText);
      };

      recognition.onerror = (event: any) => {
        console.error('âŒ Erreur reconnaissance:', event.error);
        isListeningRef.current = false;
        
        if (event.error === 'no-speech' && !isManualMode) {
          setTimeout(() => startListening(), 2000);
        } else if (event.error !== 'aborted') {
          setErrorMsg('Erreur reconnaissance vocale');
        }
      };

      recognition.onend = () => {
        console.log('ğŸ¤ Ã‰coute terminÃ©e');
        isListeningRef.current = false;
      };

      recognitionRef.current = recognition;
      recognition.start();

    } catch (err: any) {
      console.error('âŒ Erreur dÃ©marrage reconnaissance:', err);
      setErrorMsg('Microphone non accessible');
      setConnectionState(ConnectionState.ERROR);
    }
  }, [isSpeaking, isManualMode]);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // GEMINI CHAT AVEC FUNCTION CALLING
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const sendToGemini = async (userText: string) => {
    try {
      if (!geminiChatRef.current) {
        throw new Error('Gemini non initialisÃ©');
      }

      console.log('ğŸ”„ Envoi Ã  Gemini...');
      const result = await geminiChatRef.current.sendMessage(userText);
      
      // âœ… GÃ‰RER FUNCTION CALLS (corrections)
      const response = result.response;
      
      // VÃ©rifier si Gemini veut appeler la fonction
      const functionCalls = response.functionCalls();
      
      if (functionCalls && functionCalls.length > 0) {
        console.log('ğŸ”§ Function calls reÃ§us:', functionCalls);
        
        functionCalls.forEach((call: any) => {
          if (call.name === 'signaler_correction') {
            const correction: Correction = {
              originalSentence: call.args.originalSentence,
              correctedSentence: call.args.correctedSentence,
              explanation: call.args.explanation,
              errorType: call.args.errorType,
            };
            
            console.log('ğŸ“ Correction dÃ©tectÃ©e:', correction);
            
            // Ajouter Ã  la liste
            setAllCorrections(prev => [...prev, correction]);
            
            // Sauvegarder dans ToolBox
            saveCorrectionsToToolBox([correction]);
          }
        });
        
        // RÃ©pondre au function call
        const functionResponse = {
          functionResponses: functionCalls.map((call: any) => ({
            name: call.name,
            response: { result: "Correction enregistrÃ©e" }
          }))
        };
        
        // Continuer la conversation
        const finalResult = await geminiChatRef.current.sendMessage([functionResponse]);
        const finalText = finalResult.response.text();
        
        console.log('âœ… RÃ©ponse finale:', finalText);
        await speakWithGoogleTTS(finalText);
        
      } else {
        // Pas de correction, rÃ©ponse simple
        const textResponse = response.text();
        console.log('âœ… RÃ©ponse Gemini:', textResponse);
        await speakWithGoogleTTS(textResponse);
      }

      // Relancer l'Ã©coute
      if (!isManualMode) {
        console.log('â³ Attente 3s avant relance...');
        setTimeout(() => {
          if (connectionState === ConnectionState.CONNECTED && !isSpeaking) {
            console.log('âœ… Relance Ã©coute');
            startListening();
          }
        }, 3000);
      }

    } catch (err: any) {
      console.error('âŒ Erreur Gemini:', err);
      setErrorMsg('Erreur traitement IA');
      
      if (!isManualMode) {
        setTimeout(() => {
          if (connectionState === ConnectionState.CONNECTED) {
            startListening();
          }
        }, 2000);
      }
    }
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // SAUVEGARDE TOOLBOX
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const saveCorrectionsToToolBox = (corrections: Correction[]) => {
    if (corrections.length === 0) return;

    console.log('ğŸ’¾ Sauvegarde dans ToolBox:', corrections.length);

    corrections.forEach((correction) => {
      const category = correction.errorType || 'grammar';
      
      addItem({
        category: category as any,
        title: `Correction - ${category}`,
        description: correction.explanation,
        example: `âŒ "${correction.originalSentence}"\nâœ… "${correction.correctedSentence}"`,
        errorContext: `Semaine ${weekNumber} - Mode Oral`,
      });
    });

    window.dispatchEvent(new Event('toolboxUpdated'));
    setShowToolboxNotification(true);
    setTimeout(() => setShowToolboxNotification(false), 3000);
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // GOOGLE CLOUD TTS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const speakWithGoogleTTS = async (text: string) => {
    try {
      setIsSpeaking(true);
      console.log('ğŸ”Š SynthÃ¨se TTS...');

      const apiKey = import.meta.env.VITE_API_KEY;
      
      const response = await fetch(
        `https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            input: { text },
            voice: {
              languageCode: 'fr-FR',
              name: 'fr-FR-Neural2-B',
            },
            audioConfig: {
              audioEncoding: 'MP3',
              pitch: 0,
              speakingRate: 1.0
            }
          })
        }
      );

      if (!response.ok) {
        throw new Error(`TTS error: ${response.status}`);
      }

      const data = await response.json();
      await playAudioBase64(data.audioContent);

      console.log('âœ… Audio jouÃ©');
      setIsSpeaking(false);

    } catch (err: any) {
      console.error('âŒ Erreur TTS:', err);
      setIsSpeaking(false);
      await speakWithBrowserTTS(text);
    }
  };

  const speakWithBrowserTTS = async (text: string) => {
    return new Promise<void>((resolve) => {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'fr-FR';

      utterance.onend = () => {
        setIsSpeaking(false);
        resolve();
      };

      utterance.onerror = () => {
        setIsSpeaking(false);
        resolve();
      };

      speechSynthesis.speak(utterance);
    });
  };

  const playAudioBase64 = async (base64Audio: string) => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
    }

    const audioContext = audioContextRef.current;
    const binaryString = atob(base64Audio);
    const bytes = new Uint8Array(binaryString.length);
    
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }

    const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
    const source = audioContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(audioContext.destination);

    return new Promise<void>((resolve) => {
      source.onended = () => resolve();
      source.start(0);
    });
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // DÃ‰MARRAGE SESSION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const startSession = async (duration: number) => {
    try {
      setSelectedDuration(duration);
      setTimeRemaining(duration * 60);
      setShowDurationSelector(false);
      setConnectionState(ConnectionState.CONNECTING);
      setErrorMsg(null);
      setAllCorrections([]);
      setIsManualMode(false);

      await navigator.mediaDevices.getUserMedia({ audio: true });

      console.log('âœ… Session dÃ©marrÃ©e');
      setConnectionState(ConnectionState.CONNECTED);

      const greeting = `Bonjour ! Je suis FranÃ§ois. Nous travaillons sur la semaine ${weekNumber}. ${week.description}. CommenÃ§ons !`;
      await speakWithGoogleTTS(greeting);

      setTimeout(() => {
        console.log('âœ… PremiÃ¨re Ã©coute');
        startListening();
      }, 2000);

    } catch (err: any) {
      console.error('âŒ Erreur dÃ©marrage:', err);
      setErrorMsg('Impossible d\'accÃ©der au microphone');
      setConnectionState(ConnectionState.ERROR);
    }
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CLEANUP
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const cleanup = () => {
    if (recognitionRef.current) {
      try { recognitionRef.current.stop(); } catch (e) {}
      recognitionRef.current = null;
    }

    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    speechSynthesis.cancel();
    isListeningRef.current = false;

    if (timerIntervalRef.current) {
      clearInterval(timerIntervalRef.current);
    }
  };

  const handleEndCall = () => {
    cleanup();
    onClose();
  };

  const handleReportDoubt = () => {
    const elapsedTime = selectedDuration ? (selectedDuration * 60 - timeRemaining) : 0;
    
    let correctionsText = '=== CORRECTIONS ===\n\n';
    if (allCorrections.length === 0) {
      correctionsText += '(Aucune)\n\n';
    } else {
      allCorrections.forEach((c, i) => {
        correctionsText += `[${i + 1}] ${c.errorType}\n`;
        correctionsText += `   âŒ ${c.originalSentence}\n`;
        correctionsText += `   âœ… ${c.correctedSentence}\n`;
        correctionsText += `   ğŸ’¡ ${c.explanation}\n\n`;
      });
    }
    
    const subject = encodeURIComponent('ğŸš¨ Doute - Mode ORAL');
    const body = encodeURIComponent(`Bonjour Marion,

Semaine : ${week.title}
Date : ${new Date().toLocaleString('fr-FR')}
DurÃ©e : ${formatTime(elapsedTime)}

${correctionsText}

Commentaire :
(Ajoutez vos commentaires)

Cordialement`);

    window.location.href = `mailto:marionviz@hotmail.com?subject=${subject}&body=${body}`;
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RENDU UI
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  if (showDurationSelector) {
    return (
      <div className="flex flex-col h-screen max-w-4xl mx-auto bg-white">
        <header className="p-4 border-b bg-white/80">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-3">
              <img src="/francois.jpg" alt="FranÃ§ois" className="w-10 h-10 rounded-full shadow-sm object-cover" />
              <div>
                <h1 className="text-xl font-bold">
                  Lingua<span className="text-brand-green">Compagnon</span>
                </h1>
                <p className="text-xs text-gray-500">Mode Oral - Semaine {week.id}</p>
              </div>
            </div>
            <button onClick={onClose} className="px-4 py-2 bg-red-500/20 text-red-600 rounded-lg">
              â† Retour
            </button>
          </div>
        </header>

        <main className="flex-1 flex flex-col items-center justify-center p-8 bg-gray-50">
          <h2 className="text-3xl font-bold mb-4">DurÃ©e de pratique ?</h2>
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4 max-w-2xl">
            {[2, 5, 8, 10].map((d) => (
              <button
                key={d}
                onClick={() => startSession(d)}
                className="p-8 bg-white rounded-xl border-2 hover:border-brand-green hover:shadow-xl transition-all"
              >
                <div className="text-5xl font-bold text-brand-green">{d}</div>
                <div className="text-sm text-gray-600">minute{d > 1 ? 's' : ''}</div>
              </button>
            ))}
          </div>
        </main>
      </div>
    );
  }

  return (
    <div className="flex flex-col h-screen max-w-4xl mx-auto bg-white">
      {showToolboxNotification && (
        <div className="fixed top-4 right-4 z-50 bg-green-500 text-white px-6 py-3 rounded-lg shadow-xl">
          âœ… AjoutÃ© Ã  votre boÃ®te Ã  outils !
        </div>
      )}
      
      <header className="p-4 border-b bg-white/80">
        <div className="flex justify-between items-center mb-2">
          <div className="flex items-center gap-3">
            <img src="/francois.jpg" alt="FranÃ§ois" className="w-10 h-10 rounded-full shadow-sm object-cover" />
            <div>
              <h1 className="text-xl font-bold">
                Lingua<span className="text-brand-green">Compagnon</span>
              </h1>
              <p className="text-xs text-gray-500">{week.title}</p>
            </div>
          </div>
          
          <div className="flex items-center gap-2">
            <div className="px-4 py-2 bg-gray-800 rounded-lg">
              <div className="text-2xl font-bold text-brand-green">
                {formatTime(timeRemaining)}
              </div>
            </div>
            
            <button 
              onClick={handleReportDoubt}
              className="px-3 py-2 bg-orange-100 hover:bg-orange-200 text-orange-700 text-xs font-medium rounded-lg"
            >
              âš ï¸ Un doute ?
            </button>
            
            <button 
              onClick={handleEndCall} 
              className="px-4 py-2 bg-red-500 hover:bg-red-600 text-white rounded-lg"
            >
              âœ• Terminer
            </button>
          </div>
        </div>
      </header>

      <main className="flex-1 overflow-y-auto p-4 bg-gray-50">
        <div className="flex flex-col items-center justify-center min-h-[400px]">
          {connectionState === ConnectionState.CONNECTING && (
            <div className="text-center">
              <div className="w-16 h-16 border-4 border-brand-green border-t-transparent rounded-full animate-spin mx-auto mb-4"></div>
              <p>Connexion...</p>
            </div>
          )}

          {connectionState === ConnectionState.ERROR && (
            <div className="text-center">
              <div className="text-6xl mb-4">âŒ</div>
              <p className="text-red-600 mb-4">{errorMsg}</p>
              <button onClick={() => setShowDurationSelector(true)} className="px-6 py-3 bg-red-500 text-white rounded-lg">
                RÃ©essayer
              </button>
            </div>
          )}

          {connectionState === ConnectionState.CONNECTED && (
            <div className="text-center">
              <div className={`w-48 h-48 rounded-full flex items-center justify-center mb-6 shadow-2xl ${
                isSpeaking ? 'bg-gradient-to-br from-blue-400 to-cyan-500 animate-pulse' :
                isListeningRef.current ? 'bg-gradient-to-br from-purple-400 to-pink-500 animate-pulse' :
                'bg-gradient-to-br from-green-400 to-emerald-500'
              }`}>
                <div className="text-6xl text-white">
                  {isSpeaking ? 'ğŸ”Š' : isListeningRef.current ? 'ğŸ¤' : 'âœ“'}
                </div>
              </div>

              <div className="text-xl font-semibold mb-4">
                {isSpeaking ? 'FranÃ§ois parle...' : isListeningRef.current ? 'Je vous Ã©coute...' : 'PrÃªt'}
              </div>

              {transcript && (
                <div className="bg-white border rounded-lg p-4 max-w-2xl mb-4">
                  <p className="text-sm text-gray-600">Vous :</p>
                  <p className="text-gray-800">{transcript}</p>
                </div>
              )}
            </div>
          )}
        </div>

        {allCorrections.length > 0 && (
          <div className="mt-6 bg-white border rounded-lg p-4">
            <h3 className="text-sm font-bold mb-3">ğŸ“ Corrections ({allCorrections.length})</h3>
            <div className="space-y-3">
              {allCorrections.map((c, i) => (
                <div key={i} className="bg-amber-50 border-l-4 border-amber-400 p-3 rounded-r-lg">
                  <div className="text-sm text-gray-500 line-through">{c.originalSentence}</div>
                  <div className="text-sm font-semibold text-gray-800">â†’ {c.correctedSentence}</div>
                  <p className="text-xs text-gray-600 italic mt-1">ğŸ’¡ {c.explanation}</p>
                </div>
              ))}
            </div>
          </div>
        )}
      </main>

      <div className="p-4 bg-white border-t">
        <button
          onClick={() => setShowToolbox(!showToolbox)}
          className="w-full flex items-center justify-between px-4 py-3 bg-brand-green hover:bg-green-700 text-white rounded-lg"
        >
          <div className="flex items-center gap-3">
            <span>ğŸ› ï¸</span>
            <span className="font-semibold">Ma BoÃ®te Ã  Outils</span>
          </div>
          <svg className={`w-5 h-5 transition-transform ${showToolbox ? 'rotate-180' : ''}`} fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 9l-7 7-7-7" />
          </svg>
        </button>

        {showToolbox && (
          <div className="mt-4">
            <ToolBox weekNumber={weekNumber} />
          </div>
        )}
      </div>
    </div>
  );
};

export default LiveTutorOral;